{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "authorship_tag": "ABX9TyMZ5UEQehFDQ6wcE95IOl8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Machine_learning-_Algorithms-/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "im4SR7z9b6x9"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries for our project\n",
        "\n",
        "import numpy as np  # numpy is a library that helps us manipulate and handle data easily\n",
        "import pandas as pd  # pandas is a library used for working with data in a structured way, like using tables (dataframes)\n",
        "import sklearn as slt  # sklearn (also known as scikit-learn) is a tool for building machine learning models\n",
        "import matplotlib.pyplot as plt  # matplotlib is a library used to create visual representations of data (like charts and graphs)\n",
        "import seaborn as sns  # seaborn is a more advanced library for creating beautiful visualizations of data\n",
        "\n",
        "import warnings  # warnings is a module to manage warning messages in Python\n",
        "\n",
        "# Ignore all warnings that the program might generate to keep our output clean\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set the default size for all charts and graphs to 10 inches wide and 5 inches tall\n",
        "plt.rcParams['figure.figsize'] = [10, 5]\n",
        "\n",
        "# Specifically ignore warnings about features that might be removed in the future versions of libraries\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload data from my loacal\n",
        "data= pd.read_csv(\"/content/titanic_dataset.csv\")"
      ],
      "metadata": {
        "id": "LM9a3ULJikjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape#info chech How many colman  and row in data set"
      ],
      "metadata": {
        "id": "nEEJQM18jVbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head() #Show the chank of few  data"
      ],
      "metadata": {
        "id": "cMpJL7zMjth3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the histplot function from seaborn to create a histogram.\n",
        "# A histogram shows the distribution of data, in this case, the number of children with parents.\n",
        "\n",
        "# 'data['Parch']' is the column from our data that contains the number of parents or children a person has with them.\n",
        "# 'Parch' stands for \"Parents/Children\".\n",
        "\n",
        "# 'kde=False' means we do not want to include the Kernel Density Estimate line, which is a smooth line representing the distribution.\n",
        "sns.histplot(data['Parch'], kde=False)\n",
        "\n",
        "# Add a title to the histogram to make it clear what the plot represents.\n",
        "plt.title('Number of Children with Parents (Parch) Distribution')\n"
      ],
      "metadata": {
        "id": "91jqTdGGkEIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the distplot function from seaborn to create a distribution plot.\n",
        "# A distribution plot shows the distribution of data, in this case, the ages of individuals.\n",
        "\n",
        "# 'data['Age']' is the column from our data that contains the ages of individuals.\n",
        "\n",
        "# 'hist=False' means we do not want to include the histogram bars in the plot.\n",
        "# This will only show the smooth line representing the distribution of ages.\n",
        "sns.distplot(data['Age'], hist=False)\n",
        "\n",
        "# Add a title to the distribution plot to make it clear what the plot represents.\n",
        "plt.title('Age Distribution')\n"
      ],
      "metadata": {
        "id": "piCqMEkzo9QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the distplot function from seaborn to create a distribution plot.\n",
        "# A distribution plot shows the distribution of data, in this case, the ages of individuals.\n",
        "\n",
        "# 'data['Age']' is the column from our data that contains the ages of individuals.\n",
        "\n",
        "# By not setting 'hist=False', we include both the histogram bars and the smooth line in the plot.\n",
        "# The histogram bars show the frequency of ages in different ranges.\n",
        "# The smooth line represents the overall distribution of ages.\n",
        "sns.distplot(data['Age'])\n",
        "\n",
        "# Add a title to the distribution plot to make it clear what the plot represents.\n",
        "plt.title('Age Distribution')\n"
      ],
      "metadata": {
        "id": "KPEjp4I3sJjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the relplot function from seaborn to create a relational plot.\n",
        "# This type of plot shows relationships between variables.\n",
        "\n",
        "# The x-axis will represent the Age of individuals.\n",
        "# The y-axis will represent the Fare paid by individuals.\n",
        "\n",
        "# We use 'col' to create separate plots for each passenger class (Pclass).\n",
        "# This means we will have different plots for each class (e.g., 1st, 2nd, and 3rd class).\n",
        "\n",
        "# The 'hue' parameter colors the lines differently based on the Sex of individuals (e.g., male and female).\n",
        "# The 'style' parameter changes the line style based on the Sex of individuals (e.g., different types of lines for males and females).\n",
        "\n",
        "# 'kind' is set to 'line' to create a line plot, showing how Age and Fare are related over different ages.\n",
        "\n",
        "# 'data' specifies the source of our information, which is stored in the variable named 'data'.\n",
        "sns.relplot(x=\"Age\", y='Fare', col='Pclass', hue='Sex', style='Sex', kind='line', data=data)\n",
        "\n",
        "# Add a title to the plot to give it a descriptive heading.\n",
        "plt.suptitle('Relationship between Age, Sex, and Fare across Passenger Classes', y=1.05)\n"
      ],
      "metadata": {
        "id": "8dtNLanksQaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we set the size of the plot to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "# Next, we create a line plot using seaborn.\n",
        "# The x-axis will represent the Age of individuals.\n",
        "# The y-axis will represent the Fare paid by individuals.\n",
        "# We use 'hue' to color the lines differently based on the Sex of individuals (e.g., male and female).\n",
        "# 'data' specifies the source of our information, which is stored in the variable named 'data'.\n",
        "sns.lineplot(x='Age', y='Fare', hue='Sex', data=data)\n",
        "\n",
        "# Add a title to the line plot to give it a descriptive heading.\n",
        "plt.title('Line Plot of Fare by Age and Sex')\n"
      ],
      "metadata": {
        "id": "j3zZZvi9Amnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we set the size of the plot to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(8,8))\n",
        "# Next, we create a scatter plot using seaborn.\n",
        "# The x-axis will represent the Age of individuals.\n",
        "# The y-axis will represent the Fare paid by individuals.\n",
        "# We use 'hue' to color the points differently based on the Sex of individuals (e.g., male and female).\n",
        "# 'data' specifies the source of our information, which is stored in the variable named 'data'.\n",
        "sns.scatterplot(x='Age', y='Fare', hue='Sex', data=data)\n",
        "\n",
        "# Now, we add a title to the scatter plot to give it a descriptive heading.\n",
        "plt.title('Scatter Plot of Fare by Age and Sex')\n"
      ],
      "metadata": {
        "id": "vBf_4abA6H4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, set the size of the plot to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "# Next, create a bar plot using seaborn.\n",
        "# The x-axis will represent the Age of individuals.\n",
        "# The y-axis will represent the Survived column, indicating whether individuals survived (1) or not (0).\n",
        "# We use 'hue' to color the bars differently based on the Passenger Class (Pclass) of individuals (e.g., 1st, 2nd, and 3rd class).\n",
        "# 'data' specifies the source of our information, which is stored in the variable named 'data'.\n",
        "sns.barplot(x=\"Sex\", y='Survived', hue='Pclass', data=data)\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HmDZi4yuByGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the figure to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "# Use the stripplot function from seaborn to create a strip plot.\n",
        "# A strip plot displays individual data points along an axis.\n",
        "# Here, we're plotting the Age of individuals grouped by Sex.\n",
        "# Each point represents one individual's age, with different colors representing different sexes.\n",
        "sns.stripplot(x=\"Sex\", y=\"Age\", hue=\"Sex\", data=data)\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n",
        "\n",
        "# Comments for a non-technical person from Pakistan:\n",
        "# We're creating a visual representation of age distribution by gender.\n",
        "# Each point on the plot represents one person's age, with males and females shown in different colors.\n",
        "# This helps us understand how age is distributed among males and females in the dataset.\n"
      ],
      "metadata": {
        "id": "bzrjarrvF4_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the figure to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Use the swarmplot function from seaborn to create a swarm plot.\n",
        "# Swarm plots display individual data points along an axis without overlapping.\n",
        "# Here, we're plotting the Age of individuals grouped by Sex.\n",
        "# Each point represents one individual's age, with different colors representing different sexes.\n",
        "sns.swarmplot(x='Sex', y='Age', hue='Sex', data=data)\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "F4D5khgMHrll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the figure to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Use the boxplot function from seaborn to create a box plot.\n",
        "# Box plots are used to visualize the distribution of data and identify outliers.\n",
        "# Here, we're plotting the Age of individuals grouped by whether they survived (Survived column).\n",
        "# The box plot shows the median (middle line), quartiles (box), and any outliers (points outside the whiskers).\n",
        "sns.boxplot(x='Survived', y='Age', data=data)\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y-oT96MCJInq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the size of the figure to 8 inches by 8 inches to make it easier to see and read.\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Use the violinplot function from seaborn to create a violin plot.\n",
        "# Violin plots are similar to box plots but also show the probability density of the data at different values.\n",
        "# Here, we're plotting the Age of individuals grouped by whether they survived (Survived column) and colored by Sex.\n",
        "sns.violinplot(x=\"Survived\", y='Age', hue='Sex', data=data)\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4TI6OYklK46v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use seaborn's countplot function to create a bar plot showing the count of each category in the 'Survived' column.\n",
        "# The 'x' parameter specifies the column to plot, which is 'Survived' in this case.\n",
        "# The 'data' parameter specifies the dataset to use, which is 'full_data'.\n",
        "# The 'palette' parameter sets the color palette to \"Blues\" for the plot.\n",
        "sns.countplot(x=\"Survived\", data=data, palette=\"Blues\")\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Cwa-2Hy3NhZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new figure and subplots with a size of 8 inches by 8 inches.\n",
        "plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# Use seaborn's pointplot function to create a point plot.\n",
        "# Point plots show point estimates and confidence intervals as lines, making comparisons between groups easier.\n",
        "# Here, we're plotting the proportion of individuals who survived (Survived) by Sex, with different colors representing Passenger Class (Pclass).\n",
        "sns.pointplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=data)\n",
        "\n",
        "# Display the plot.\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "udtUHw7xPOp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np  # Import numpy library for numerical computations\n",
        "import pandas as pd  # Import pandas library for data manipulation and analysis\n",
        "import matplotlib.pyplot as plt  # Import matplotlib library for data visualization\n",
        "%matplotlib inline\n",
        "import seaborn as sns  # Import seaborn library for advanced data visualization\n",
        "import sklearn  # Import sklearn library for machine learning tools\n",
        "import warnings  # Import warnings module to manage warnings\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set the default figure size for matplotlib plots\n",
        "plt.rcParams[\"figure.figsize\"] = [10, 5]\n",
        "\n",
        "# Ignore FutureWarnings\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "9HixZsUXTibF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the dataset is named 'titanic_dataset.csv' and located at '/content/'\n",
        "data = pd.read_csv(\"/content/titanic_dataset.csv\")"
      ],
      "metadata": {
        "id": "XMHfQa0VVU3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying information about the dataset\n",
        "# This function provides an overview of the DataFrame, including the number of non-null values and data types of each column\n",
        "# It's useful for understanding the structure of the dataset without delving into technical details\n",
        "data.info()\n"
      ],
      "metadata": {
        "id": "duk5RqqBW1-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a heatmap to visualize null values in the dataset\n",
        "# A heatmap is a graphical representation of data where the values of a matrix are represented as colors\n",
        "# Here, we're using seaborn library to create the heatmap\n",
        "\n",
        "\n",
        "# Plotting the heatmap to visualize null values\n",
        "# The isnull() function checks for null values in the DataFrame, and then the heatmap function from seaborn is used to visualize these null values\n",
        "# cmap='viridis' sets the color palette for the heatmap\n",
        "# cbar=False removes the color bar on the side\n",
        "# yticklabels=False removes the y-axis tick labels for better readability\n",
        "sns.heatmap(data.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
        "plt.title('Null Values Heatmap')  # Adding a title to the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JYNvgymbXqpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation function\n",
        "# This function handles missing values in the 'Age' column by estimating ages based on passenger class.\n",
        "# If the 'Age' value is missing, it assigns an estimated age based on the 'Pclass' value.\n",
        "# Estimated ages:\n",
        "#   - For Pclass 1: 37\n",
        "#   - For Pclass 2: 29\n",
        "#   - For other Pclass values: 24\n",
        "# If the 'Age' value is not missing, it remains unchanged.\n",
        "\n",
        "def impute_age(cols):\n",
        "    Age = cols[0]\n",
        "    Pclass = cols[1]\n",
        "\n",
        "    # Check if 'Age' value is missing\n",
        "    if pd.isnull(Age):\n",
        "        # Assign estimated age based on 'Pclass'\n",
        "        if Pclass == 1:\n",
        "            return 37\n",
        "        elif Pclass == 2:\n",
        "            return 29\n",
        "        else:\n",
        "            return 24\n",
        "    else:\n",
        "        return Age\n",
        "\n",
        "# Apply the imputation function to the 'Age' column\n",
        "# This line applies the 'impute_age' function to each row of the 'Age' column in the dataset 'data',\n",
        "# using the 'Pclass' column as additional input.\n",
        "data['Age'] = data[['Age', 'Pclass']].apply(impute_age, axis=1)\n"
      ],
      "metadata": {
        "id": "zXt1JiOvhGt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'Cabin' feature from the dataset\n",
        "# This line of code deletes the 'Cabin' column from the dataset named 'data'.\n",
        "# axis=1 specifies that we are removing a column (not a row).\n",
        "# inplace=True means the dataset 'data' is modified directly without creating a new dataset.\n",
        "\n",
        "data.drop(\"Cabin\", axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "kI26d1yujdD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a heatmap to visualize null values in the dataset\n",
        "# A heatmap is a graphical representation of data where the values of a matrix are represented as colors\n",
        "# Here, we're using seaborn library to create the heatmap\n",
        "\n",
        "\n",
        "# Plotting the heatmap to visualize null values\n",
        "# The isnull() function checks for null values in the DataFrame, and then the heatmap function from seaborn is used to visualize these null values\n",
        "# cmap='viridis' sets the color palette for the heatmap\n",
        "# cbar=False removes the color bar on the side\n",
        "# yticklabels=False removes the y-axis tick labels for better readability\n",
        "sns.heatmap(data.isnull(), cmap='viridis', cbar=False, yticklabels=False)\n",
        "plt.title('Null Values Heatmap')  # Adding a title to the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6gq1rwHYjJIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a box plot to check for outliers in the dataset\n",
        "# A box plot is a standardized way of displaying the distribution of data based on a five-number summary: minimum, first quartile (Q1), median (Q2), third quartile (Q3), and maximum\n",
        "# Outliers are typically identified as points that fall outside the whiskers of the box plot\n",
        "\n",
        "import matplotlib.pyplot as plt  # Importing matplotlib library for data visualization\n",
        "\n",
        "# Plotting a box plot to check for outliers\n",
        "# The boxplot() function from matplotlib is used to create the box plot\n",
        "# The data argument specifies the DataFrame to be plotted\n",
        "# vert=False specifies horizontal orientation for the box plot\n",
        "# whis=1.5 sets the whisker length to 1.5 times the interquartile range, which is a common threshold for identifying outliers\n",
        "# patch_artist=True fills the boxes with colors for better visualization\n",
        "# showmeans=True displays the mean value as a point in the box plot\n",
        "data.boxplot(vert=False, whis=1.5, patch_artist=True, showmeans=True)\n",
        "plt.title('Box Plot for Outlier Detection')  # Adding a title to the plot\n",
        "plt.xlabel('Value')  # Labeling the x-axis\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bRcFu7EHZOlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#write the  code check the outlier from"
      ],
      "metadata": {
        "id": "hysT1N9qdr7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.boxplot(x = 'Pclass', y = 'Age', data = data , palette= 'GnBu_d').set_title('Age by Passenger Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uly2YGFbdSE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "NgmiyFyst8nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply data redaction to improve the quality of the dataset for training the model\n",
        "# This step involves removing or modifying data to ensure that the dataset is clean and suitable for model training.\n",
        "# Remove the 'PassengerId' and 'Name' columns from the dataset\n",
        "# This line of code deletes the 'PassengerId' and 'Name' columns from the dataset named 'data'.\n",
        "# axis=1 specifies that we are removing columns (not rows).\n",
        "# inplace=True means the dataset 'data' is modified directly without creating a new dataset.\n",
        "\n",
        "data.drop(['PassengerId', 'Name','Ticket'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KWyD7urhuSDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables into 'dummy' or indicator variables Assing numarcal value categorcal  varaibe\n",
        "sex = pd.get_dummies(data['Sex'], drop_first = True) # drop_first prevents multi-collinearity\n",
        "embarked = pd.get_dummies(data['Embarked'], drop_first = True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uShPijIBE4mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new dummy columns to organal data set\n",
        "data = pd.concat([data, sex, embarked], axis = 1)\n",
        "data.head(5)"
      ],
      "metadata": {
        "id": "NI9vmHNkI_cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unecessary columns from data set\n",
        "data.drop(['Sex', 'Embarked'], axis = 1, inplace = True)\n",
        "\n",
        "# Shape of train data\n",
        "print('train_data shape',data.shape)\n",
        "\n",
        "# Confirm changes\n",
        "data.head()"
      ],
      "metadata": {
        "id": "tt7buA01Jdp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all values in a DataFrame column to integer data type\n",
        "data['male'] = data['male'].astype(int)\n"
      ],
      "metadata": {
        "id": "TASJE3h9LHb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all values in a DataFrame column to integer data type\n",
        "data['S'] = data['S'].astype(int)\n",
        "# Convert all values in a DataFrame column to integer data type\n",
        "data['Q'] = data['Q'].astype(int)"
      ],
      "metadata": {
        "id": "EjjclxatLVY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "1eRtvOJHLRI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sparate the Feauter and target Variable  feature Represents x and Y Representation  Traget Vraibe\n",
        "#Drop the 'Survived' column from the DataFrame and assign the remaining data to variable x\n",
        "# This step is used to select the features (input variables) for our model\n",
        "x = data.drop('Survived', axis=1)\n",
        "\n",
        "# Select the 'Survived' column from the DataFrame and assign it to variable y\n",
        "# This step is used to select the target variable (output variable) for our model\n",
        "y = data['Survived']\n"
      ],
      "metadata": {
        "id": "6xK_vxZUMZKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Feature Scaling technique to convert values into a specific range\n",
        "# Import preprocessing module from sklearn\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Fit the StandardScaler to the feature data\n",
        "pre_process = preprocessing.StandardScaler().fit(x)\n",
        "\n",
        "# Transform the feature data using the fitted StandardScaler\n",
        "x_transformed = pre_process.transform(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "2MWXLaRyX8YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the original and transformed values\n",
        "print(\"Original values:\")\n",
        "print(x.head())  # Display the first few rows of the original feature data\n",
        "\n",
        "print(\"\\nTransformed values:\")\n",
        "print(x_transformed[:5])  # Display the first few rows of the transformed feature data"
      ],
      "metadata": {
        "id": "syFu1RdKaKCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split from sklearn library\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "# test_size=0.2 indicates 20% of the data will be used for testing\n",
        "# random_state=101 pic data randomly  from data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)\n",
        "\n",
        "# Display the sizes of the training and testing sets\n",
        "print(\"Training feature set size:\", x_train.shape)\n",
        "print(\"Testing feature set size:\", x_test.shape)\n",
        "print(\"Training target set size:\", y_train.shape)\n",
        "print(\"Testing target set size:\", y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "h_4RUDPpbQxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply classification algorithm LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Print a message to indicate which model is being used\n",
        "print(\"Logistic Regression\")\n",
        "\n",
        "# Create an instance of the LogisticRegression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Train the model using the training data\n",
        "log_reg.fit(x_train, y_train)\n",
        "\n",
        "# The model is now trained and ready to make predictions\n"
      ],
      "metadata": {
        "id": "5dGfJTkJjQgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use accuracy metric to check the accuracy of the model during training\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict the target values using the trained logistic regression model on the test data\n",
        "y_pred_log_reg = log_reg.predict(x_test)\n",
        "\n",
        "# Print a message to indicate which model's accuracy we are checking\n",
        "print(\"Logistic Regression\")\n",
        "\n",
        "# Print a separator for better readability\n",
        "print('-' * 30)\n",
        "\n",
        "# Calculate the accuracy of the logistic regression model\n",
        "# accuracy_score compares the true target values (y_test) with the predicted values (y_pred_log_reg)\n",
        "log_reg_accuracy = round(accuracy_score(y_test, y_pred_log_reg) * 100, 2)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(\"Accuracy:\", log_reg_accuracy, \"%\")\n"
      ],
      "metadata": {
        "id": "-i-L0KJ-mItt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Decision Tree classifier algorithm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Print a message to indicate which model is being used\n",
        "print('Decision Tree Classifier')\n",
        "\n",
        "# Create an instance of the Decision Tree classifier\n",
        "Dtree = DecisionTreeClassifier()\n",
        "\n",
        "# Train the Decision Tree model using the training data\n",
        "Dtree.fit(x_train, y_train)\n",
        "\n",
        "# The model is now trained and ready to make predictions\n"
      ],
      "metadata": {
        "id": "RuiHcPtvqB0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use accuracy metric to check the accuracy of the model during training\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict the target values using the trained logistic regression model on the test data\n",
        "y_pred_Dtree = Dtree.predict(x_test)\n",
        "\n",
        "# Print a message to indicate which model's accuracy we are checking\n",
        "print(\"DecisionTreeClassifier\")\n",
        "\n",
        "# Print a separator for better readability\n",
        "print('-' * 30)\n",
        "\n",
        "# Calculate the accuracy of the logistic regression model\n",
        "# accuracy_score compares the true target values (y_test) with the predicted values (y_pred_log_reg)\n",
        "Dtree_accuracy = round(accuracy_score(y_test, y_pred_Dtree) * 100, 2)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print(\"Accuracy:\", Dtree_accuracy, \"%\")\n"
      ],
      "metadata": {
        "id": "5squldUhr7N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Random Forest Classifier model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Print a message to indicate which model is being used\n",
        "print(\"Random Forest Classifier\")\n",
        "\n",
        "# Create an instance of the Random Forest Classifier\n",
        "rfc = RandomForestClassifier()\n",
        "\n",
        "# Train the Random Forest model using the training data\n",
        "rfc.fit(x_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "5F2vgiww2XQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Accuracy  Score Matrix and Cakeck The Accray of model\n",
        "from sklearn.metrics import  accuracy_score\n",
        "\n",
        "#Pridict the Traget  value using that train model random _forest\n",
        "y_pred_rfc= rfc.predict(x_test)\n",
        "print(\"Random Forests\")\n",
        "\n",
        "print(\"--\"*30)\n",
        "\n",
        "rfc_accuracy=round(accuracy_score(y_test,y_pred_rfc)*100,2)\n",
        "\n",
        "print(\"Accuracy:\",rfc_accuracy,\"%\")\n"
      ],
      "metadata": {
        "id": "18aT-xOi4YTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Gradient Boosting Classifier model\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Print a message to indicate which model is being used\n",
        "print(\"Gradient Boosting Classifier\")\n",
        "\n",
        "# Create an instance of the Gradient Boosting Classifier\n",
        "gbc = GradientBoostingClassifier()\n",
        "\n",
        "# Train the Gradient Boosting model using the training data\n",
        "gbc.fit(x_train, y_train)\n",
        "\n",
        "# The model is now trained and ready to make predictions\n"
      ],
      "metadata": {
        "id": "vUY-KGez7VHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Accuracy  Score Matrix and Cakeck The Accray of model\n",
        "from sklearn.metrics import  accuracy_score\n",
        "\n",
        "#Pridict the Traget  value using that train model random _forest\n",
        "y_pred_gbc= gbc.predict(x_test)\n",
        "print(\"Gradient Boosting Classifer\")\n",
        "\n",
        "\n",
        "print(\"--\"*30)\n",
        "\n",
        "gbc_accuracy=round(accuracy_score(y_test,y_pred_gbc)*100,2)\n",
        "\n",
        "print(\"Accuracy:\",gbc_accuracy,\"%\")\n"
      ],
      "metadata": {
        "id": "fFoPhUwn8gyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary containing the accuracy scores of different models\n",
        "model_scores = {\n",
        "    \"Logistic Regression\": log_reg_accuracy,  # Accuracy of Logistic Regression model\n",
        "    \"Decision Tree\": Dtree_accuracy,         # Accuracy of Decision Tree model\n",
        "    \"Random Forest\": rfc_accuracy,           # Accuracy of Random Forest model\n",
        "    \"Gradient Boosting\": gbc_accuracy        # Accuracy of Gradient Boosting model\n",
        "}\n",
        "\n",
        "# Sort the model scores in descending order (from highest to lowest accuracy)\n",
        "sorted_model_scores = sorted(model_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "# Print the sorted model scores\n",
        "print(\"\\nModel Scores:\")\n",
        "for model, score in sorted_model_scores:\n",
        "    # Print each model name and its accuracy percentage\n",
        "    print(f\"{model}: {score}%\")\n"
      ],
      "metadata": {
        "id": "aW_odw029azp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}